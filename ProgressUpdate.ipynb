{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GEOS 505 Research Computing in Earth System Science \n",
    "# Final Project: Progress Update\n",
    "***\n",
    "\n",
    "### D. Kody Johnson                                  \n",
    "### November 29, 2018\n",
    "---\n",
    "\n",
    "## Introduction & Background\n",
    "\n",
    "In the previous submittal (Dataset Overview), two scripts were developed. The first script comprised a set of ABAQUS commands to conduct a parametric study of the strain response of an AREMA 132R rail section to applied vertical and lateral loads. The vertical and lateral loads were varied for each simulation in an effort to find the strain (based on nodal deformations) of eight (8) ‘virtual’ strain gauges. The corresponding nodal deformations were then output to an output file (.dat file) for post processing to calculate the respective shear strains.\n",
    "\n",
    "In the second script, the differential shear strain due to the applied loading for a single simulation was determined. The shear strain was then related to the applied loading through material and geometric properties of the rail section according to the differential shear theory presented in the Problem Statement submittal. This step was a validation that the nodal deformations were properly used to correctly calculate the principle strains  and differential shear. \n",
    "\n",
    "## Updated Workflow\n",
    "\n",
    "In this submittal, the script developed for a single simulation was expanded to iterate through all simulation output files to calculate the eight (8) corresponding principle strain values. These values represent the features or predictors of a training data set used as the input to a machine learning algorithm. Each sample of this training dataset corresponds to each of the simulations in which both horizontal and vertical load were varied from zero (0) load to 250 kN. The load combinations of vertical and lateral load used in each simulation are the response variables in the training dataset. The training data will be used in the next submittal to determine two mapping functions: one for the vertical load and one for the lateral load. \n",
    "\n",
    "The following code gathers the nodal deformations corresponding to each strain gauge from the simulation output data files, validates that the principle strains are properly calculated, and constructs an array of vertical load, lateral load, and the eight strain values. Note: the code has been commented extensively to describe the various steps carried out in the script. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[     0.        ]\n",
      " [ 50322.60875946]\n",
      " [100646.76858273]\n",
      " [150972.02216487]\n",
      " [201298.64769655]\n",
      " [251626.12337242]]\n",
      "\n",
      "\n",
      "[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-6.36416530e-05  6.48792191e-05  6.48553059e-05 -6.36542249e-05\n",
      "  -6.36929522e-05  6.48632837e-05  6.48671253e-05 -6.36823365e-05]\n",
      " [-1.27171936e-04  1.29875771e-04  1.29822288e-04 -1.27197574e-04\n",
      "  -1.27275623e-04  1.29840040e-04  1.29848601e-04 -1.27256216e-04]\n",
      " [-1.90591954e-04  1.94984635e-04  1.94902920e-04 -1.90631523e-04\n",
      "  -1.90746367e-04  1.94933616e-04  1.94941033e-04 -1.90719122e-04]\n",
      " [-2.53899564e-04  2.60209539e-04  2.60095938e-04 -2.53957057e-04\n",
      "  -2.54105793e-04  2.60138625e-04  2.60148263e-04 -2.54073531e-04]\n",
      " [-3.17094359e-04  3.25547955e-04  3.25401818e-04 -3.17171522e-04\n",
      "  -3.17352372e-04  3.25462152e-04  3.25467037e-04 -3.17316919e-04]\n",
      " [ 3.16649020e-04 -1.03112516e-06 -1.03628151e-05  2.89240714e-04\n",
      "  -2.36472391e-04  3.83394374e-05  4.59658365e-05 -2.02734288e-04]\n",
      " [ 2.53017860e-04  6.37836926e-05  5.44370440e-05  2.25571699e-04\n",
      "  -3.00166900e-04  1.03246090e-04  1.10894030e-04 -2.66444658e-04]\n",
      " [ 1.89497785e-04  1.28714608e-04  1.19349587e-04  1.62012028e-04\n",
      "  -3.63751455e-04  1.68266578e-04  1.75936810e-04 -3.30045944e-04]\n",
      " [ 1.26090563e-04  1.93758470e-04  1.84376174e-04  9.85621596e-05\n",
      "  -4.27225058e-04  2.33402338e-04  2.41091364e-04 -3.93539342e-04]\n",
      " [ 6.27930287e-05  2.58919010e-04  2.49515143e-04  3.52234856e-05\n",
      "  -4.90585425e-04  2.98653140e-04  3.06360378e-04 -4.56920477e-04]\n",
      " [-3.89919081e-07  3.24193695e-04  3.14766357e-04 -2.80048445e-05\n",
      "  -5.53836310e-04  3.64017878e-04  3.71739665e-04 -5.20191826e-04]\n",
      " [ 7.13570155e-04  3.52749523e-05  1.49287082e-05  6.65108476e-04\n",
      "  -3.92540761e-04  1.14010100e-04  1.27578358e-04 -3.18712225e-04]\n",
      " [ 6.49952829e-04  1.00022422e-04  7.96721815e-05  6.01430724e-04\n",
      "  -4.56233751e-04  1.78957494e-04  1.92566199e-04 -3.82446258e-04]\n",
      " [ 5.86449971e-04  1.64886715e-04  1.44528137e-04  5.37861852e-04\n",
      "  -5.19814756e-04  2.44020042e-04  2.57667172e-04 -4.46070376e-04]\n",
      " [ 5.23057927e-04  2.29862089e-04  2.09497916e-04  4.74402678e-04\n",
      "  -5.83284845e-04  3.09196006e-04  3.22882880e-04 -5.09583670e-04]\n",
      " [ 4.59775721e-04  2.94955500e-04  2.74578715e-04  4.11054095e-04\n",
      "  -6.46641908e-04  3.74487802e-04  3.88209490e-04 -5.72988633e-04]\n",
      " [ 3.96608333e-04  3.60162216e-04  3.39774260e-04  3.47813754e-04\n",
      "  -7.09888617e-04  4.39893046e-04  4.53647919e-04 -6.36283604e-04]\n",
      " [ 1.19066278e-03  1.08915469e-04  7.58737143e-05  1.12751049e-03\n",
      "  -4.68171086e-04  2.27004917e-04  2.44829631e-04 -3.47903091e-04]\n",
      " [ 1.12706822e-03  1.73593604e-04  1.40558023e-04  1.06382698e-03\n",
      "  -5.31854531e-04  2.91990937e-04  3.09874667e-04 -4.11654521e-04]\n",
      " [ 1.06358507e-03  2.38386393e-04  2.05354931e-04  1.00025442e-03\n",
      "  -5.95427767e-04  3.57090709e-04  3.75032751e-04 -4.75295532e-04]\n",
      " [ 1.00021373e-03  3.03293384e-04  2.70264256e-04  9.36789438e-04\n",
      "  -6.58889273e-04  4.22305261e-04  4.40303944e-04 -5.38827288e-04]\n",
      " [ 9.36953841e-04  3.68317646e-04  3.35284854e-04  8.73437243e-04\n",
      "  -7.22238077e-04  4.87634322e-04  5.05686439e-04 -6.02249324e-04]\n",
      " [ 8.73806624e-04  4.33454192e-04  4.00423657e-04  8.10194110e-04\n",
      "  -7.85476356e-04  5.53080743e-04  5.71182709e-04 -6.65562805e-04]\n",
      " [ 1.74781784e-03  2.19880605e-04  1.72466176e-04  1.67632120e-03\n",
      "  -4.63339742e-04  3.77308816e-04  3.97705544e-04 -2.90299660e-04]\n",
      " [ 1.68424729e-03  2.84487331e-04  2.37088004e-04  1.61263943e-03\n",
      "  -5.27011282e-04  4.42331043e-04  4.62806506e-04 -3.54062017e-04]\n",
      " [ 1.62079306e-03  3.49208653e-04  3.01822480e-04  1.54906803e-03\n",
      "  -5.90571238e-04  5.07466868e-04  5.28017991e-04 -4.17716657e-04]\n",
      " [ 1.55744664e-03  4.14043843e-04  3.66670321e-04  1.48560623e-03\n",
      "  -6.54018476e-04  5.72718571e-04  5.93343580e-04 -4.81258915e-04]\n",
      " [ 1.49421207e-03  4.78994786e-04  4.31631640e-04  1.42225372e-03\n",
      "  -7.17355322e-04  6.38082573e-04  6.58781905e-04 -5.44691401e-04]\n",
      " [ 1.43109089e-03  5.44059555e-04  4.96705901e-04  1.35901133e-03\n",
      "  -7.80585014e-04  7.03572301e-04  7.24333986e-04 -6.08007863e-04]\n",
      " [ 2.38489833e-03  3.68160207e-04  3.04691174e-04  2.31139976e-03\n",
      "  -3.78051973e-04  5.64907898e-04  5.86192262e-04 -1.45918106e-04]\n",
      " [ 2.32136261e-03  4.32692670e-04  3.69251295e-04  2.24772781e-03\n",
      "  -4.41703841e-04  6.29962448e-04  6.51344439e-04 -2.09684959e-04]\n",
      " [ 2.25793615e-03  4.97336162e-04  4.33921197e-04  2.18416229e-03\n",
      "  -5.05245524e-04  6.95131612e-04  7.16609362e-04 -2.73344400e-04]\n",
      " [ 2.19462131e-03  5.62100084e-04  4.98706231e-04  2.12070664e-03\n",
      "  -5.68675734e-04  7.60416919e-04  7.81987006e-04 -3.36894412e-04]\n",
      " [ 2.13141806e-03  6.26973248e-04  5.63603101e-04  2.05736128e-03\n",
      "  -6.31995572e-04  8.25816903e-04  8.47478613e-04 -4.00331873e-04]\n",
      " [ 2.06832800e-03  6.91964673e-04  6.28612460e-04  1.99412473e-03\n",
      "  -6.95204267e-04  8.91331485e-04  9.13080400e-04 -4.63665799e-04]]\n",
      "\n",
      "\n",
      "[[     0.      0.]\n",
      " [ 50000.      0.]\n",
      " [100000.      0.]\n",
      " [150000.      0.]\n",
      " [200000.      0.]\n",
      " [250000.      0.]\n",
      " [     0.  50000.]\n",
      " [ 50000.  50000.]\n",
      " [100000.  50000.]\n",
      " [150000.  50000.]\n",
      " [200000.  50000.]\n",
      " [250000.  50000.]\n",
      " [     0. 100000.]\n",
      " [ 50000. 100000.]\n",
      " [100000. 100000.]\n",
      " [150000. 100000.]\n",
      " [200000. 100000.]\n",
      " [250000. 100000.]\n",
      " [     0. 150000.]\n",
      " [ 50000. 150000.]\n",
      " [100000. 150000.]\n",
      " [150000. 150000.]\n",
      " [200000. 150000.]\n",
      " [250000. 150000.]\n",
      " [     0. 200000.]\n",
      " [ 50000. 200000.]\n",
      " [100000. 200000.]\n",
      " [150000. 200000.]\n",
      " [200000. 200000.]\n",
      " [250000. 200000.]\n",
      " [     0. 250000.]\n",
      " [ 50000. 250000.]\n",
      " [100000. 250000.]\n",
      " [150000. 250000.]\n",
      " [200000. 250000.]\n",
      " [250000. 250000.]]\n"
     ]
    }
   ],
   "source": [
    "#This script takes coordinate and displacement data for nodes representing\n",
    "#   virtual strain gauges on a small section of AREMA 132RE rail and calculates\n",
    "#   the infinitesimal strain that would be measured by these strain gauges due\n",
    "#   to applied vertical and lateral loads. \n",
    "\n",
    "#import necessary libraries\n",
    "import os    #\n",
    "import numpy as np\n",
    "import re\n",
    "#import sklearn.gaussian_process as GP #These libraries will be used in the \n",
    "#import sklearn.linear_model as LM     #   next submittal\n",
    "\n",
    "# Import original coordinates to an ndarray. All 'gauge' nodes are within\n",
    "#   first 50 nodes in the file (as numbered by ABAQUS). Not all 50 are used, and\n",
    "#   they must be reorganized into a consistent pattern for calculation. The \n",
    "#   conventioned used is as follows: starting at location A on the right side,\n",
    "#   the first node is the upper right node of th gauge element and the second\n",
    "#   node is the lower left (+45 degrees). The third node is the lower right and\n",
    "#   the fourth node is the upper left (-45 degrees). This pattern is repeated \n",
    "#   for location B on the right side, then location A on the left side and \n",
    "#   finally location B on the left side (16 nodes in total).\n",
    "\n",
    "with open('orig_coords.txt') as f:\n",
    "    lines = f.readlines()\n",
    "OC = np.zeros([len(lines),4],dtype=float)    #Original Coordinate array\n",
    "for i in range(0,len(lines),1):\n",
    "    OC[i] = np.fromstring(lines[i],dtype=float,sep = \",\")\n",
    "OC = np.vstack(OC)\n",
    "\n",
    "# Reorganize the nodes into pattern described above\n",
    "\n",
    "OP = np.zeros([16,3],dtype=float)    #Original Point array\n",
    "for i in range(0,50,1):\n",
    "    if OC[i,0] == 49.:\n",
    "        OP[0,:] = OC[i,1:4]\n",
    "    elif OC[i,0] == 15.:\n",
    "        OP[1,:] = OC[i,1:4]\n",
    "    elif OC[i,0] == 8.:\n",
    "        OP[2,:] = OC[i,1:4]\n",
    "    elif OC[i,0] == 45.:\n",
    "        OP[3,:] = OC[i,1:4]\n",
    "    elif OC[i,0] == 37.:\n",
    "        OP[4,:] = OC[i,1:4]\n",
    "    elif OC[i,0] == 20.:\n",
    "        OP[5,:] = OC[i,1:4]\n",
    "    elif OC[i,0] == 16.:\n",
    "        OP[6,:] = OC[i,1:4] \n",
    "    elif OC[i,0] == 40.:\n",
    "        OP[7,:] = OC[i,1:4]\n",
    "    elif OC[i,0] == 50.:\n",
    "        OP[8,:] = OC[i,1:4]\n",
    "    elif OC[i,0] == 14.:\n",
    "        OP[9,:] = OC[i,1:4]\n",
    "    elif OC[i,0] == 5.:\n",
    "        OP[10,:] = OC[i,1:4]\n",
    "    elif OC[i,0] == 46.:\n",
    "        OP[11,:] = OC[i,1:4]\n",
    "    elif OC[i,0] == 38.:\n",
    "        OP[12,:] = OC[i,1:4]\n",
    "    elif OC[i,0] == 19.:\n",
    "        OP[13,:] = OC[i,1:4]\n",
    "    elif OC[i,0] == 13.:\n",
    "        OP[14,:] = OC[i,1:4]\n",
    "    elif OC[i,0] == 39.:\n",
    "        OP[15,:] = OC[i,1:4]      \n",
    "\n",
    "#Create a list of .dat file names to be used with open()\n",
    "\n",
    "file_list = [] #Initialize filer list.\n",
    "folder = [] #Initialize folder list.\n",
    "for dirName, subdirList, fileList in os.walk('.'): #Use OS.walk to walk each folder and directory and create a path name     \n",
    "    for fname in fileList:                         #to each file.\n",
    "        if fname.endswith(\".dat\"): \n",
    "           path = dirName + '\\\\' + fname          #Build windows readable path neam.\n",
    "           file_list = file_list + [path]\n",
    "\n",
    "\n",
    "# Read and organize the file_list array in the same order the ABAQUS parametric\n",
    "#   study used (defined in the 'design_definitions.txt' file) OS walk opens the \n",
    "#   files in alphanumeric order and so the design number (i.e. c1, c2,... c36)  \n",
    "#   in the file name is used to relate the order of the file_list list to the  \n",
    "#   order defined in the 'design_definitions.txt' file.\n",
    "           \n",
    "des = np.zeros([len(file_list),1],dtype=int)    #design array (desing number)\n",
    "pat1 = re.compile(r\"_c\")          \n",
    "for i in range (0,len(file_list),1):\n",
    "    if pat1.search(file_list[i]) != None:   #Only open .dat files with _c in \n",
    "        pat2 = re.compile(r'\\d+')           #   the name. This step is not\n",
    "        desn = pat2.findall(file_list[i])   #   necessary as all other .dat \n",
    "        des[i,0] = int(desn[0])             #   files have been removed\n",
    "\n",
    "# The des array is a list of design numbers (e.g. c1, c2 etc.) read from the \n",
    "#   file_list array. The next section uses this array to reorganize the \n",
    "#   file_list \n",
    "\n",
    "des = np.vstack(des[:,0].argsort())\n",
    "count = -1\n",
    "flist = np.vstack([None]*len(file_list))   #Ordered file_list array\n",
    "for ind in des:\n",
    "    count = count + 1\n",
    "    flist[count] = file_list[ind[0]]\n",
    "flist = flist.flatten()\n",
    "flist = flist.tolist()\n",
    "\n",
    "# Using the flist array, open each file and read the displacement data. The \n",
    "#   .dat files have 3/4 of a million lines of code and the location of the \n",
    "#   nodal displacement data may not be at the same location. Therefore, a \n",
    "#   regular expresson is used to search for a line of text preceeding the \n",
    "#   section in the .dat files that contains the displacement data. Once read,\n",
    "#   the data is reogainzed in the same order as the OC (original coordinate)\n",
    "#   array.     \n",
    "   \n",
    "U = np.zeros([16,3,len(flist)],dtype=float)  # Ordered Displacements (U)      \n",
    "CD = np.zeros([16,4],dtype=float)     # Unordered Coordinate Displacements (CD)\n",
    "for i in range(0,len(flist),1):\n",
    "    with open(flist[i]) as f:\n",
    "        lines = f.readlines()\n",
    "        pat = re.compile(r\"\\bINCREMENT     6 SUMMARY\\b\")\n",
    "        for j in range(0,len(lines),1):\n",
    "            if pat.search(lines[j]) != None:\n",
    "                disp = lines[j+19:j+35]    #Temporary displacement array (disp)\n",
    "        for k in range(0,len(disp),1):\n",
    "            CD[k] = np.fromstring(disp[k],dtype=float,sep = \" \")\n",
    "        CD = np.vstack(CD)\n",
    "        for p in range(0,16,1):\n",
    "            if CD[p,0] == 49.:\n",
    "                U[0,:,i] = CD[p,1:4]\n",
    "            elif CD[p,0] == 15.:\n",
    "                U[1,:,i] = CD[p,1:4]\n",
    "            elif CD[p,0] == 8.:\n",
    "                U[2,:,i] = CD[p,1:4]\n",
    "            elif CD[p,0] == 45.:\n",
    "                U[3,:,i] = CD[p,1:4]\n",
    "            elif CD[p,0] == 37.:\n",
    "                U[4,:,i] = CD[p,1:4]\n",
    "            elif CD[p,0] == 20.:\n",
    "                U[5,:,i] = CD[p,1:4]\n",
    "            elif CD[p,0] == 16.:\n",
    "                U[6,:,i] = CD[p,1:4] \n",
    "            elif CD[p,0] == 40.:\n",
    "                U[7,:,i] = CD[p,1:4]\n",
    "            elif CD[p,0] == 50.:\n",
    "                U[8,:,i] = CD[p,1:4]\n",
    "            elif CD[p,0] == 14.:\n",
    "                U[9,:,i] = CD[p,1:4]\n",
    "            elif CD[p,0] == 5.:\n",
    "                U[10,:,i] = CD[p,1:4]\n",
    "            elif CD[p,0] == 46.:\n",
    "                U[11,:,i] = CD[p,1:4]\n",
    "            elif CD[p,0] == 38.:\n",
    "                U[12,:,i] = CD[p,1:4]\n",
    "            elif CD[p,0] == 19.:\n",
    "                U[13,:,i] = CD[p,1:4]\n",
    "            elif CD[p,0] == 13.:\n",
    "                U[14,:,i] = CD[p,1:4]\n",
    "            elif CD[p,0] == 39.:\n",
    "                U[15,:,i] = CD[p,1:4] \n",
    "        \n",
    "# Calculate the infinitesimal strain of each 'virtual' strain gauge (as\n",
    "#   previously defined). This is done by first creating a Deformed Point (DP)\n",
    "#   in which is the displacement is added to the original point. Using this \n",
    "#   set of points and the OC set of points, two sets of lines are created:\n",
    "#   Original line (OL) and Deformed Line (DL). These lines are then used to \n",
    "#   calculate infinitesimal strain according to the strain definition.\n",
    "\n",
    "ST = np.zeros([8,len(flist)],dtype=float)   # Strain array\n",
    "P = np.zeros([len(flist),1],dtype=float)    # Estimated vertical load (to be\n",
    "for i in range(0,len(flist),1):             #   described later)\n",
    "    DP = np.zeros([16,3],dtype=float)   #Deformed point\n",
    "    DP = OP + U[:,:,i]                          \n",
    "    \n",
    "    OL = np.zeros([8,1],dtype=float)    #Original line\n",
    "    DL = np.zeros([8,1],dtype=float)    #Deformed line\n",
    "    \n",
    "    for j in range(0,8,1):\n",
    "        OL[j,0] = np.linalg.norm(OP[2*j+1,:]-OP[2*j,:])\n",
    "        DL[j,0] = np.linalg.norm(DP[2*j+1,:]-DP[2*j,:])\n",
    "    strain = (DL - OL)/OL    #Definition of infitesimal strain.\n",
    "    ST[:,i] = strain.reshape(8,)\n",
    "  \n",
    "# As a check to ensure that all strains were calculated correctly, the vertical\n",
    "#   load P, estimated using the differential shear approach (described else-\n",
    "#   where), is calculated and compared to the applied loads. Note: the first 6\n",
    "#   elements of P correspond to cases in which the lateral load is zero; it is\n",
    "#   only for these cases that the calculation will provide accurate results as\n",
    "#   crosstalk from the lateral load causes an error in the differential shear \n",
    "#   calculation. \n",
    "\n",
    "# Principle strains on the right side (ea, eb, ec, ed; see Figure 1)\n",
    "    \n",
    "    ea = ST[0]\n",
    "    eb = ST[1]\n",
    "    ec = ST[2]\n",
    "    ed = ST[3]\n",
    "    eap = ST[4]\n",
    "    ebp = ST[5]\n",
    "    ecp = ST[6]\n",
    "    edp = ST[7]\n",
    "    \n",
    "    e1 = (eb + ebp)/2 - (ea + eap)/2\n",
    "    e2 = (ec + ecp)/2 - (ed + edp)/2\n",
    "          \n",
    "    delG = e1 + e2\n",
    "    \n",
    "    E = 2.07E+11\n",
    "    I = 3.661E-05\n",
    "    t = 0.0173795\n",
    "    Q = 0.000258773\n",
    "    v = 0.30\n",
    "    \n",
    "    \n",
    "    P[i,0] = E*I*t/(2*Q*(1+v))*delG[i]\n",
    "    \n",
    "vert=[]\n",
    "lat=[]\n",
    "pat = re.compile(r'\\d+')\n",
    "with open('design_definitions.txt') as f:\n",
    "    lines = f.readlines()\n",
    "    for i in range(0,len(lines),1):\n",
    "       line = lines[i]\n",
    "       loads = pat.findall(line)\n",
    "       vert = vert + [float(loads[1])]\n",
    "       lat = lat + [float(loads[3])]\n",
    "    loads = np.column_stack((vert,lat))\n",
    "    ST = np.transpose(ST)\n",
    "    #tr_data = np.hstack((loads,ST))   #convenient for copy/paste to other platforms.\n",
    "    X = ST\n",
    "    y = loads\n",
    "    print(P[0:6,:])\n",
    "    print('\\n')\n",
    "    print(X)\n",
    "    print('\\n')\n",
    "    print(y)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
